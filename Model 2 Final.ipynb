{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Epic-SK/dpuplusippy/blob/main/Model%202%20Final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VTvr4_sti9Am"
      },
      "source": [
        "# Inroduction\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rm8HKcygh4L2"
      },
      "source": [
        "This sample notebook demonstrates how to process live data streams using Pathway. The dataset used here is a subset of the one provided â€” specifically, it includes data for only a single parking spot. You are expected to implement your model across all parking spots.\n",
        "\n",
        "Please note that the pricing model used in this notebook is a simple baseline. You are expected to design and implement a more advanced and effective model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LlwkKnB50IGF"
      },
      "outputs": [],
      "source": [
        "!pip install pathway bokeh --quiet # This cell may take a few seconds to execute."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pHuc1nkJveN3"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "from tabulate import tabulate\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import datetime\n",
        "from datetime import datetime\n",
        "import pathway as pw\n",
        "import bokeh.plotting\n",
        "from bokeh.layouts import gridplot\n",
        "from bokeh.plotting import figure, output_file, show\n",
        "from bokeh.io import curdoc\n",
        "import panel as pn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def haversine(lat1, lon1, lat2, lon2):\n",
        "\n",
        "    # distance between latitudes\n",
        "    # and longitudes\n",
        "    dLat = (lat2 - lat1) * math.pi / 180.0\n",
        "    dLon = (lon2 - lon1) * math.pi / 180.0\n",
        "\n",
        "    # convert to radians\n",
        "    lat1 = (lat1) * math.pi / 180.0\n",
        "    lat2 = (lat2) * math.pi / 180.0\n",
        "\n",
        "    # apply formulae\n",
        "    a = (pow(math.sin(dLat / 2), 2) +\n",
        "         pow(math.sin(dLon / 2), 2) *\n",
        "             math.cos(lat1) * math.cos(lat2));\n",
        "    rad = 6371\n",
        "    c = 2 * math.asin(math.sqrt(a))\n",
        "    return rad * c"
      ],
      "metadata": {
        "id": "Wq50_kfacv9W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gGpZl1FxjFXE"
      },
      "source": [
        "# Step 1: Importing and Preprocessing the Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4D6geoV9veN3"
      },
      "outputs": [],
      "source": [
        "pd.set_option('future.no_silent_downcasting', True)\n",
        "\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/Epic-SK/dpuplusippy/refs/heads/main/Modified%20-%20modified.csv')\n",
        "maindf = pd.read_csv('https://raw.githubusercontent.com/Epic-SK/dpuplusippy/refs/heads/main/dataset.csv')\n",
        "df.head()\n",
        "# You can find the sample dataset here: https://drive.google.com/file/d/1D479FLjp9aO3Mg8g6Lpj9oRViWacurA6/view?usp=sharing"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#df = maindf\n",
        "maindf.head()"
      ],
      "metadata": {
        "id": "5zCuKCtyorWd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QBrvlQTjveN4"
      },
      "outputs": [],
      "source": [
        "# Combine the 'LastUpdatedDate' and 'LastUpdatedTime' columns into a single datetime column\n",
        "\n",
        "\n",
        "df['Timestamp'] = pd.to_datetime(df['LastUpdatedDate'] + ' ' + df['LastUpdatedTime'],\n",
        "                                  format='%d-%m-%Y %H:%M:%S')\n",
        "df['Timestamp'] = df['Timestamp'].dt.round(freq='30min')\n",
        "# Sort the DataFrame by the new 'Timestamp' column and reset the index\n",
        "df = df.sort_values('Timestamp').reset_index(drop=True)\n",
        "df['VehicleType'] = df['VehicleType'].replace({'cycle': 0, 'bike': 1, 'car': 2, 'truck':3}, regex=True)\n",
        "df['TrafficConditionNearby'] = df['TrafficConditionNearby'].replace({'low': 0, 'average': 1, 'high': 2}, regex=True)\n",
        "\n",
        "Longitudes = maindf['Longitude'].unique()\n",
        "Latitudes = maindf['Latitude'].unique()\n",
        "print(Latitudes, Longitudes)\n",
        "p = figure(width=400, height=400)\n",
        "\n",
        "# add a circle renderer with a size, color, and alpha\n",
        "p.scatter(Latitudes, Longitudes, size=20, color=\"navy\", alpha=0.5)\n",
        "\n",
        "output_file(\"dark_minimal.html\")\n",
        "curdoc().theme = 'dark_minimal'\n",
        "\n",
        "# show the results\n",
        "show(p)\n",
        "\n",
        "distances = np.zeros((14,14), dtype = 'float')\n",
        "for i in range(14):\n",
        "  for j in range(14):\n",
        "    distances[i,j] = np.round(haversine(Latitudes[i], Longitudes[i], Latitudes[j], Longitudes[j]),2)\n",
        "table = tabulate(distances, tablefmt=\"fancy_grid\")\n",
        "print(table)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c52UkGGpveN5"
      },
      "outputs": [],
      "source": [
        "# Save the selected columns to a CSV file for streaming or downstream processing\n",
        "df[[\"SystemCodeNumber\", \"Timestamp\", \"Occupancy\", \"Capacity\", \"QueueLength\", \"TrafficConditionNearby\", \"IsSpecialDay\", \"VehicleType\"]].to_csv(\"parking_stream.csv\", index=False)\n",
        "# Note: Only three features are used here for simplicity.\n",
        "# Participants are expected to incorporate additional relevant features in their models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H0pe3TGIyKJE"
      },
      "outputs": [],
      "source": [
        "# Define the schema for the streaming data using Pathway\n",
        "# This schema specifies the expected structure of each data row in the stream\n",
        "\n",
        "class ParkingSchema(pw.Schema):\n",
        "    SystemCodeNumber: str\n",
        "    Timestamp: str   # Timestamp of the observation (should ideally be in ISO format)\n",
        "    Occupancy: int   # Number of occupied parking spots\n",
        "    Capacity: int    # Total parking capacity at the location\n",
        "    QueueLength : int\n",
        "    TrafficConditionNearby : int\n",
        "    IsSpecialDay :int\n",
        "    VehicleType : int\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a4LxMh4xziMv"
      },
      "outputs": [],
      "source": [
        "# Load the data as a simulated stream using Pathway's replay_csv function\n",
        "# This replays the CSV data at a controlled input rate to mimic real-time streaming\n",
        "# input_rate=1000 means approximately 1000 rows per second will be ingested into the stream.\n",
        "\n",
        "data = pw.demo.replay_csv(\"parking_stream.csv\", schema=ParkingSchema, input_rate=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IkBP_AA-zjec"
      },
      "outputs": [],
      "source": [
        "# Define the datetime format to parse the 'Timestamp' column\n",
        "fmt = \"%Y-%m-%d %H:%M:%S\"\n",
        "\n",
        "# Add new columns to the data stream:\n",
        "# - 't' contains the parsed full datetime\n",
        "# - 'day' extracts the date part and resets the time to midnight (useful for day-level aggregations)\n",
        "data_with_time = data.with_columns(\n",
        "    t = data.Timestamp.dt.strptime(fmt),\n",
        "    day = data.Timestamp.dt.strptime(fmt).dt.strftime(\"%Y-%m-%dT00:00:00\")\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JNDR7r4DqkhI"
      },
      "source": [
        "# Step 2: Making a simple pricing function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MznsSjanveN5"
      },
      "outputs": [],
      "source": [
        "# Define a daily tumbling window over the data stream using Pathway\n",
        "# This block performs temporal aggregation and computes a dynamic price for each day\n",
        "import datetime\n",
        "\n",
        "delta_window = (\n",
        "    data_with_time.windowby(\n",
        "        pw.this.t,  # Event time column to use for windowing (parsed datetime)\n",
        "        instance=pw.this.day,  # Logical partitioning key: one instance per calendar day\n",
        "        window=pw.temporal.tumbling(datetime.timedelta(days=1)),  # Fixed-size daily window\n",
        "        behavior=pw.temporal.exactly_once_behavior()  # Guarantees exactly-once processing semantics\n",
        "    )\n",
        "    .reduce(\n",
        "        t=pw.this._pw_window_end,                        # Assign the end timestamp of each window\n",
        "        occ_max=pw.reducers.max(pw.this.Occupancy),      # Highest occupancy observed in the window\n",
        "        occ_min=pw.reducers.min(pw.this.Occupancy),      # Lowest occupancy observed in the window\n",
        "        cap=pw.reducers.max(pw.this.Capacity),           # Maximum capacity observed (typically constant per spot)\n",
        "        que=pw.reducers.avg(pw.this.QueueLength),\n",
        "        trf=pw.reducers.avg(pw.this.TrafficConditionNearby),\n",
        "        spl=pw.reducers.max(pw.this.IsSpecialDay),\n",
        "        veh=pw.reducers.avg(pw.this.VehicleType),\n",
        "        scn=pw.reducers.any(pw.this.SystemCodeNumber)\n",
        "\n",
        "    )\n",
        "    .with_columns(\n",
        "        # Compute the price using a simple dynamic pricing formula:\n",
        "        #\n",
        "        # Pricing Formula:\n",
        "        #     price = base_price + demand_fluctuation\n",
        "        #     where:\n",
        "        #         base_price = 10 (fixed minimum price)\n",
        "        #         demand_fluctuation = (occ_max - occ_min) / cap\n",
        "        #\n",
        "        # Intuition:\n",
        "        # - The greater the difference between peak and low occupancy in a day,\n",
        "        #   the more volatile the demand is, indicating potential scarcity.\n",
        "        # - Dividing by capacity normalizes the fluctuation (to stay in [0,1] range).\n",
        "        # - This fluctuation is added to the base price of 10 to set the final price.\n",
        "        # - Example: If occ_max = 90, occ_min = 30, cap = 100\n",
        "        #            => price = 10 + (90 - 30)/100 = 10 + 0.6 = 10.6\n",
        "\n",
        "        price=10 + 1.5 * (3 * (pw.this.occ_max - pw.this.occ_min) / pw.this.cap - 0.5 * pw.this.que + 2 * pw.this.trf + pw.this.spl + (pw.this.veh - 1.5)).num.round(1)\n",
        "    )\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E3sMSFtUqvax"
      },
      "source": [
        "# Step 3: Visualizing Daily Price Fluctuations with a Bokeh Plot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "POd-S7QMo9JA"
      },
      "source": [
        "**Note:** The Bokeh plot in the next cell will only be generated after you run the `pw.run()` cell (i.e., the final cell).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fOL3BJcGveN5"
      },
      "outputs": [],
      "source": [
        "# Activate the Panel extension to enable interactive visualizations\n",
        "pn.extension()\n",
        "\n",
        "# Define a custom Bokeh plotting function that takes a data source (from Pathway) and returns a figure\n",
        "def price_plotter(source, lot):\n",
        "    # Create a Bokeh figure with datetime x-axis\n",
        "    output_file(\"dark_minimal.html\")\n",
        "    curdoc().theme = 'dark_minimal'\n",
        "\n",
        "    fig = bokeh.plotting.figure(\n",
        "        height=400,\n",
        "        width=800,\n",
        "        title=\"Pathway: Daily Parking Price\",\n",
        "        x_axis_type=\"datetime\",  # Ensure time-based data is properly formatted on the x-axis\n",
        "    )\n",
        "    # Plot a line graph showing how the price evolves over time\n",
        "    fig.line(\"t\", \"price\", source=source, line_width=2, color=\"navy\")\n",
        "\n",
        "    # Overlay red circles at each data point for better visibility\n",
        "    fig.scatter(\"t\", \"price\", source=source, size=6, color=\"red\")\n",
        "\n",
        "    return fig\n",
        "\n",
        "# Use Pathway's built-in .plot() method to bind the data stream (delta_window) to the Bokeh plot\n",
        "# - 'price_plotter' is the rendering function\n",
        "# - 'sorting_col=\"t\"' ensures the data is plotted in time order\n",
        "unique_lots = df[\"SystemCodeNumber\"].dropna().unique()\n",
        "panels = []\n",
        "\n",
        "filtered = delta_window.filter(pw.this.scn == unique_lots[0])\n",
        "viz = filtered.plot(lambda src: price_plotter(src, unique_lots[0]), sorting_col=\"t\")\n",
        "\n",
        "# Create a Panel layout and make it servable as a web app\n",
        "# This line enables the interactive plot to be displayed when the app is served\n",
        "pn.Column(viz).servable()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "uxvr-QOiurwi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0IHWGcX6veN6"
      },
      "outputs": [],
      "source": [
        "# Start the Pathway pipeline execution in the background\n",
        "# - This triggers the real-time data stream processing defined above\n",
        "# - %%capture --no-display suppresses output in the notebook interface\n",
        "\n",
        "%%capture --no-display\n",
        "pw.run()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pklSMqmRp1Gh"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "datasetId": 7749157,
          "sourceId": 12294858,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 31040,
      "isGpuEnabled": false,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}